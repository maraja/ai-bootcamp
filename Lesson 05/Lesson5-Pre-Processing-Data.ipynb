{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"width:450px;\" src=\"https://durhamcollege.ca/wp-content/uploads/ai-hub-header.jpg\" alt=\"DC Logo\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LESSON 5 - Pre-Processing Data\n",
    "## <span style=\"color: green\">OVERVIEW</span>\n",
    "\n",
    "Many machine learning algorithms make assumptions about your data.\n",
    "\n",
    "It is often a very good idea to prepare your data in such way to best expose the structure of the problem to the machine learning algorithms that you intend to use.\n",
    "\n",
    "In this post you will discover how to prepare your data for machine learning in Python using the scikit-learn library. Which contains tools for data mining and analysis that are built on NumPy, SciPy, and matplotlib.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Need for Data Processing\n",
    "\n",
    "You almost always need to pre-process your data. It is a required step.\n",
    "\n",
    "A common difficulty when processing is that different algorithms make different assumptions about your data and may require different transforms. Further, when you follow all of the rules and prepare your data, sometimes algorithms can still deliver better results without the pre-processing.\n",
    "\n",
    "Generally, I would recommend creating many different views and transforms of your data, then exercise a handful of algorithms on each view of your dataset. This will help you to flush out which data transforms might be better at exposing the structure of your problem in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Machine Learning Recipes\n",
    "\n",
    "**This section lists 4 different data preprocessing recipes for machine learning.**\n",
    "\n",
    "All of the recipes were designed to be complete and standalone.\n",
    "\n",
    "You can copy and paste them directly into your project and start working.\n",
    "\n",
    "**Note:** \n",
    "\n",
    "- <span style=\"color: blue\">**Answer any questions in bold and blue in the code block(cell) below each section.** </span>\n",
    "  \n",
    "- <span style=\"color: green\">*Any statements in italic and green are for consideration and should help guide you to understand the code involved.* </span>\n",
    "\n",
    "**The Pima Indian diabetes dataset is used in each recipe.**\n",
    "\n",
    "This is a binary classification problem where all of the attributes are numeric and have different scales. It is a great example of dataset that can benefit from pre-processing.\n",
    "\n",
    "**You can learn more about this data set on the UCI Machine Learning Repository webpage.**\n",
    "- (https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "**Each recipe follows the same structure:**\n",
    "\n",
    "1. Load the dataset from a URL.\n",
    "2. Split the dataset into the input and output variables for machine learning.\n",
    "3. Apply a preprocessing transform to the input variables.\n",
    "4. Summarize the data to show the change.\n",
    "5. The transforms are calculated in such a way that they can be applied to your    training data and any samples of data you may have in the future.\n",
    "\n",
    "**The *scikit-learn* documentation has some information on how to use various different preprocessing methods.**\n",
    "- (http://scikit-learn.org/stable/modules/preprocessing.html) \n",
    "\n",
    "**You can review the preprocess API in scikit-learn here.**\n",
    "- (http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green\">SECTION 1</span>\n",
    "### Re-scale Data\n",
    "\n",
    "When your data is comprised of attributes with varying scales, many machine learning algorithms can benefit from rescaling the attributes to all have the same scale.\n",
    "\n",
    "Often this is referred to as normalization and attributes are often rescaled into the range between 0 and 1. This is useful for optimization algorithms used in the core of machine learning algorithms like gradient descent. It is also useful for algorithms that weight inputs like regression and neural networks and algorithms that use distance measures like K-Nearest Neighbors.\n",
    "\n",
    "**You can rescale your data using scikit-learn using the *MinMaxScaler* class.**\n",
    "- (http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.353  0.744  0.59   0.354  0.     0.501  0.234  0.483]\n",
      " [ 0.059  0.427  0.541  0.293  0.     0.396  0.117  0.167]\n",
      " [ 0.471  0.92   0.525  0.     0.     0.347  0.254  0.183]\n",
      " [ 0.059  0.447  0.541  0.232  0.111  0.419  0.038  0.   ]\n",
      " [ 0.     0.688  0.328  0.354  0.199  0.642  0.944  0.2  ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import scipy\n",
    "import numpy\n",
    "\n",
    "# Rescale data (between 0 and 1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "\n",
    "array = dataframe.values\n",
    "\n",
    "# separate array into input and output components\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "# display a summary of the Rescaled data\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***After rescaling you can see that all of the values are in the range between 0 and 1.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green\">SECTION 2</span>\n",
    "### Standardize Data\n",
    "\n",
    "Standardization is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1.\n",
    "- (https://en.wikipedia.org/wiki/Normal_distribution)\n",
    "\n",
    "It is most suitable for techniques that assume a Gaussian distribution in the input variables and work better with rescaled data, such as linear regression, logistic regression and linear discriminate analysis.\n",
    "\n",
    "\n",
    "**You can standardize data using *scikit-learn* with the *StandardScaler* class.**\n",
    "- (http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64   0.848  0.15   0.907 -0.693  0.204  0.468  1.426]\n",
      " [-0.845 -1.123 -0.161  0.531 -0.693 -0.684 -0.365 -0.191]\n",
      " [ 1.234  1.944 -0.264 -1.288 -0.693 -1.103  0.604 -0.106]\n",
      " [-0.845 -0.998 -0.161  0.155  0.123 -0.494 -0.921 -1.042]\n",
      " [-1.142  0.504 -1.505  0.907  0.766  1.41   5.485 -0.02 ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# Standardize data (0 mean, 1 stdev)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "\n",
    "# Separate array into input and output components\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "\n",
    "# display a summary of the Standardized data\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The values for each attribute now have a mean value of 0 and a standard deviation of 1.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green\">SECTION 3</span>\n",
    "### Normalize Data\n",
    "\n",
    "Normalizing in scikit-learn refers to rescaling each observation (row) to have a length of 1 (called a unit norm in linear algebra).\n",
    "\n",
    "This preprocessing can be useful for sparse datasets (lots of zeros) with attributes of varying scales when using algorithms that weight input values such as neural networks and algorithms that use distance measures such as K-Nearest Neighbors.\n",
    "\n",
    "**You can normalize data in Python with *scikit-learn* using the *Normalizer* class.**\n",
    "- (http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.034  0.828  0.403  0.196  0.     0.188  0.004  0.28 ]\n",
      " [ 0.008  0.716  0.556  0.244  0.     0.224  0.003  0.261]\n",
      " [ 0.04   0.924  0.323  0.     0.     0.118  0.003  0.162]\n",
      " [ 0.007  0.588  0.436  0.152  0.622  0.186  0.001  0.139]\n",
      " [ 0.     0.596  0.174  0.152  0.731  0.188  0.01   0.144]]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# Normalize data (length of 1)\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "\n",
    "array = dataframe.values\n",
    "\n",
    "# separate array into input and output components\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "# create new scaler for transformation\n",
    "# using the sklearn normalizer function\n",
    "xscaler = Normalizer().fit(X)\n",
    "\n",
    "normalizedX = xscaler.transform(X)\n",
    "\n",
    "# set the print values to 3 decimal places\n",
    "numpy.set_printoptions(precision=3)\n",
    "# display a summary of the Normalized data\n",
    "print(normalizedX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The rows are normailzed to length 1.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green\">SECTION 4</span>\n",
    "### Binarize Data - Make it Binary \n",
    "***also known as One-Hot Encoding***\n",
    "\n",
    "You can transform your data using a binary threshold. All values above the threshold are marked 1 and all equal to or below are marked as 0.\n",
    "\n",
    "This is called binarizing your data or threshold your data. It can be useful when you have probabilities that you want to make crisp values. It is also useful when feature engineering and you want to add new features that indicate something meaningful.\n",
    "\n",
    "**You can create new binary attributes in Python using *scikit-learn* with the *Binarizer* class.**\n",
    "- (http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Binarizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  1.  0.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  0.  1.  1.  1.]\n",
      " [ 1.  1.  1.  0.  0.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.  1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# Binarize data (0 for lower threshold or 1 for upper threshold)\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "\n",
    "array = dataframe.values\n",
    "\n",
    "# separate array into input and output components\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "\n",
    "binaryX = binarizer.transform(X)\n",
    "\n",
    "# display a summary of the Binarized data\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(binaryX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***You can see that all values equal or less than 0 are marked 0 and all of those above 0 are marked 1.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green\">SUMMARY</span>\n",
    "\n",
    "In this post you discovered how you can prepare your data for machine learning in Python using ***scikit-learn***.\n",
    "\n",
    "**You now have recipes to:**\n",
    "\n",
    "- **Re-scale** data.\n",
    "- **Standardize** data.\n",
    "- **Normalize** data.\n",
    "- **Binarize** data.\n",
    "\n",
    "<center>**Now it is your turn to practice data pre-processing in *scikit-learn*!**</center>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <span style=\"color: green\">CHALLENGE</span>\n",
    "\n",
    "<span style=\"color: blue\">**For each of the 4 Pre-Processing Techniques Above**</span>\n",
    "\n",
    "- *Assess the 'Occupancy' dataset*\n",
    "- *Provided in the **'datatraining.txt'** file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# file = 'datatraining.txt'\n",
    "# occupancy_data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: blue\">Re-scale a *new* dataframe from the Occupancy data</span>\n",
    "- Reference the dataset and turn it into a dataframe with relevant column identities\n",
    "- Select the columns valid for Rescaling in a subframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rescale data (between 0 and 1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Determine a viable range for re-scaling the data in your new subframe (experiment)\n",
    "- Use sklearn to Re-scale the subframe based on your determined range\n",
    "- Display the changes in a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate or assign subframe components\n",
    "\n",
    "# display a summary of the Rescaled data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: blue\">Standardize a *new* dataframe from the Occupancy data</span>\n",
    "- Reference the dataset and turn it into a dataframe with relevant column identities\n",
    "- Select the columns valid for Standardization in a subframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize data (0 mean, 1 stdev)\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use sklearn to Standardize the subframe based on a mean of 0 and stdev of 1 (experiment)\n",
    "- Display the changes in a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate or assign subframe components\n",
    "\n",
    "# display a summary of the Standardized data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: blue\">Normalize a *new* dataframe from the Occupancy data</span>\n",
    "- Reference the dataset and turn it into a dataframe with relevant column identities\n",
    "- Select the columns valid for Normalization in a subframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize data (length of 1)\n",
    "from sklearn.preprocessing import Normalizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use sklearn to Normalize the subframe based on a length of 1 (experiment)\n",
    "- Display the changes in a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate or assign subframe components\n",
    "\n",
    "# display a summary of the Normalized data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: blue\">Binarize a *new* dataframe from the Occupancy data</span>\n",
    "- Reference the dataset and turn it into a dataframe with relevant column identities\n",
    "- Select the columns valid for Binarization in a subframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Binarize data (0 for lower threshold or 1 for upper threshold)\n",
    "from sklearn.preprocessing import Binarizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Determine a viable threshold for binarizing the data in your new subframe (experiment)\n",
    "- Use sklearn to Binarize the subframe based on your determined threshold's\n",
    "- Display the changes in a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate or assign subframe components\n",
    "\n",
    "# display a summary of the Binarized data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
